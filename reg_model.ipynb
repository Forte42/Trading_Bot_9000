{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d2986-8f0f-4112-b2a2-03b767dffc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from dotenv import load_dotenv\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "from alpaca.data.historical import CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.requests import CryptoLatestQuoteRequest\n",
    "from alpaca.data.requests import CryptoTradesRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib import math\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f52a9",
   "metadata": {},
   "source": [
    "## Data Retreival/Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f825e-3b85-4576-9416-686c4c1c822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "# alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91637821-f0fc-4c21-9ce4-c7ff383aecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(alpaca_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e11ecf-535d-43e9-a2c8-25231333ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_client = CryptoHistoricalDataClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5c4e2-8dd6-439f-be3f-dee63af334e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_params = CryptoBarsRequest(\n",
    "    symbol_or_symbols=[\"ETH/USD\"],\n",
    "    timeframe=TimeFrame.Minute, start='2022-06-30 00:00:00'\n",
    ")\n",
    "\n",
    "eth_bars = crypto_client.get_crypto_bars(request_params)\n",
    "\n",
    "eth_df = eth_bars.df\n",
    "\n",
    "eth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a2c0d-1047-4e64-9fc6-b1f8ac1b0dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_df = eth_df.reset_index()\n",
    "eth_df = eth_df.set_index('timestamp')\n",
    "eth_df = eth_df.drop(columns=['symbol'])\n",
    "\n",
    "eth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pct_change function to generate  returns from close prices\n",
    "eth_df[\"Actual Returns\"] = eth_df[\"close\"].pct_change()\n",
    "\n",
    "# Drop na\n",
    "eth_df=eth_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the sma_fast and sma_slow columns to a features DataFrame called X\n",
    "X = eth_df[['open', 'high','low','close','volume', 'trade_count']].shift().dropna()\n",
    "# Review the DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(X)), X[['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29be38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb8a6",
   "metadata": {},
   "source": [
    "### Data Split for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get array representation of dataframe\n",
    "dataset = eth_df.values\n",
    "\n",
    "# get number of rows to train the model on\n",
    "training_data_len = math.ceil(len(dataset) * 0.8)\n",
    "\n",
    "training_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdaef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataset\n",
    "train_data = X_scaled[0:training_data_len, :]\n",
    "\n",
    "# Create blank array\n",
    "X_train = []\n",
    "candles = 60\n",
    "\n",
    "for i in range(candles, len(train_data)):\n",
    "    X_train.append(train_data[i-candles:i, 0:6])\n",
    "\n",
    "\n",
    "# create test dataset\n",
    "test_data = X_scaled[training_data_len - candles: , :]\n",
    "\n",
    "# Create blank array\n",
    "X_test = []\n",
    "\n",
    "for i in range(candles, len(test_data)):\n",
    "    X_test.append(test_data[i-candles:i, 0:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to array\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "display(X_train.shape)\n",
    "display(len(X_train))\n",
    "display(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e85d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = eth_df['Actual Returns']\n",
    "\n",
    "# Review the value counts\n",
    "display(y)\n",
    "\n",
    "# Drop first row\n",
    "# y = y.iloc[1:-candles]\n",
    "y.iloc[candles+1:]\n",
    "\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a369845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Y data\n",
    "\n",
    "y_train = y.iloc[0:len(X_train)]\n",
    "y_test = y.iloc[len(X_train):]\n",
    "\n",
    "display(y_train.count())\n",
    "display(y_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737757e8",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35482cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X.columns)\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35540597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1\n",
    "\n",
    "#Define the number of hidden nodes for the first hidden layer\n",
    "# hidden_nodes_layer1 = (number_input_features + 1) // 2\n",
    "hidden_nodes_layer1 = 64\n",
    "\n",
    "# Define hidden nodes for all hidden layers\n",
    "hidden_nodes = math.ceil(((number_input_features+1)*2)/3)\n",
    "display(hidden_nodes)\n",
    "\n",
    "# Review the number hidden nodes in the first layer\n",
    "display(hidden_nodes_layer1)\n",
    "\n",
    "#Define the number of hidden nodes for the second hidden layer\n",
    "# hidden_nodes_layer2 = (hidden_nodes_layer1 + 1) //2\n",
    "hidden_nodes_layer2 = 64\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n",
    "display(hidden_nodes_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd184fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(LSTM(units=hidden_nodes_layer1, return_sequences=True, input_shape=(candles,len(X.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add dropout layer\n",
    "nn.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the second hidden layer\n",
    "nn.add(LSTM(units=hidden_nodes_layer2, return_sequences=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32535ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add dropout layer\n",
    "nn.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ad807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add the third hidden layer\n",
    "nn.add(LSTM(units=hidden_nodes_layer2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74381da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer\n",
    "nn.add(Dropout(rate=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b293aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dense layer\n",
    "# nn.add(Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bfb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=1,  activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32137c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Sequential model summary, subclassed model requires build\n",
    "nn.build(X_train.shape)\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278bc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "\n",
    "nn.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using epochs and the training data\n",
    "regr_model = nn.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27737358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model predictionis\n",
    "\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction results\n",
    "\n",
    "plt.plot(range(len(y_test)), y_test)\n",
    "plt.plot(range(len(y_test)), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9607f67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0193224db03a40cbeeb1d1467a8281023d0cf41b04cb80c5135a7c4428e4098"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
